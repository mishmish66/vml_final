{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=False\n"
     ]
    }
   ],
   "source": [
    "%set_env XLA_PYTHON_CLIENT_PREALLOCATE False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7OMXh0-BsJyN"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import jax_verify\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107351,
     "status": "ok",
     "timestamp": 1731101669341,
     "user": {
      "displayName": "Fatima Tourk",
      "userId": "02048723961878231607"
     },
     "user_tz": 300
    },
    "id": "n2iYYED5sWDB",
    "outputId": "a3d5a328-e73a-473a-b18a-944e4b14d943"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing trial: 01\n",
      "Trial 01 has 28612 common headers, proceeding with merge.\n",
      "Number of NaN values in merged_sensor_data before merging with conditions: 5285765\n",
      "NaN values detected in merged data for trial 01, dropping rows with NaN.\n",
      "Number of NaN values in merged_data for trial 01 after dropping: 0\n",
      "First few rows of merged data for trial 01:\n",
      "      Header  gastrocmed  tibialisanterior    soleus  vastusmedialis  \\\n",
      "716   15.570   -0.063153         -0.002946  0.224090       -0.010610   \n",
      "717   15.575   -0.043159         -0.000679  0.562477        0.014191   \n",
      "718   15.580    0.309805          0.003162  0.501198        0.013440   \n",
      "2943  26.705   -0.015926         -0.024213  0.038289       -0.000549   \n",
      "2944  26.710   -0.019323          0.019561  0.046283        0.001949   \n",
      "\n",
      "      vastuslateralis  rectusfemoris  bicepsfemoris  semitendinosus  gracilis  \\\n",
      "716         -0.000409       0.014828      -0.008367       -0.025644 -0.000704   \n",
      "717         -0.005238      -0.002204       0.000862        0.007756  0.002029   \n",
      "718         -0.001762       0.011672       0.026228        0.008536 -0.007330   \n",
      "2943         0.011229       0.016871      -0.017203       -0.009557 -0.107184   \n",
      "2944         0.002463       0.003084      -0.006526        0.026951  0.083696   \n",
      "\n",
      "      ...  L_Thigh_Front_x  L_Thigh_Front_y  L_Thigh_Front_z      C_28_x  \\\n",
      "716   ...       361.935669       784.119751      -893.540344  610.097656   \n",
      "717   ...       359.565338       782.822205      -890.833496  614.334351   \n",
      "718   ...       357.409119       782.511169      -885.749939  603.347839   \n",
      "2943  ...       380.584961       766.642517      -948.324463  821.136475   \n",
      "2944  ...       378.740936       764.800476      -951.791809  710.910339   \n",
      "\n",
      "           C_28_y      C_28_z      C_29_x       C_29_y      C_29_z  Speed  \n",
      "716   1056.031860 -747.555664  693.340942   995.715027 -911.236755    0.5  \n",
      "717   1166.146362 -624.559814  798.266235   953.691895 -775.739075    0.5  \n",
      "718   1056.058350 -744.226807  679.646362  1001.836243 -912.126221    0.5  \n",
      "2943   918.167908 -794.674133  618.443298  1017.935303 -766.094604    0.5  \n",
      "2944   955.405823 -926.751831  623.982605  1020.755127 -761.569763    0.5  \n",
      "\n",
      "[5 rows x 221 columns]\n",
      "\n",
      "Processing trial: 02\n",
      "Trial 02 has 28646 common headers, proceeding with merge.\n",
      "Number of NaN values in merged_sensor_data before merging with conditions: 4969374\n",
      "NaN values detected in merged data for trial 02, dropping rows with NaN.\n",
      "Number of NaN values in merged_data for trial 02 after dropping: 0\n",
      "First few rows of merged data for trial 02:\n",
      "   Header  gastrocmed  tibialisanterior    soleus  vastusmedialis  \\\n",
      "0   9.865    0.009727         -0.088719  0.000050       -0.006778   \n",
      "1   9.870   -0.039117          0.258462  0.008873       -0.000657   \n",
      "2   9.875    0.108440         -0.023157 -0.048215       -0.017579   \n",
      "3   9.880   -0.015583         -0.027177 -0.061690       -0.006605   \n",
      "4   9.885    0.048255         -0.002426  0.028457        0.004161   \n",
      "\n",
      "   vastuslateralis  rectusfemoris  bicepsfemoris  semitendinosus  gracilis  \\\n",
      "0        -0.004149       0.008284       0.009880       -0.030193 -0.013366   \n",
      "1         0.009065       0.000037      -0.018636       -0.006098  0.002955   \n",
      "2         0.006474       0.007827       0.012412       -0.020451  0.027153   \n",
      "3         0.014443      -0.004480      -0.011581        0.007568  0.017636   \n",
      "4         0.001488       0.005481       0.003087       -0.000111 -0.003863   \n",
      "\n",
      "   ...  L_Toe_Tip_x  L_Toe_Tip_y  L_Toe_Tip_z  L_Toe_Med_x  L_Toe_Med_y  \\\n",
      "0  ...   474.423370    35.222069  -935.919128   502.883270    12.773875   \n",
      "1  ...   474.408966    35.195988  -935.862610   502.904327    12.768229   \n",
      "2  ...   474.450226    35.148037  -935.923096   502.842194    12.744310   \n",
      "3  ...   474.539948    35.087490  -935.937134   502.897308    12.498606   \n",
      "4  ...   474.575226    35.037971  -935.977844   502.773834    12.290135   \n",
      "\n",
      "   L_Toe_Med_z  L_Toe_Lat_x  L_Toe_Lat_y  L_Toe_Lat_z   Speed  \n",
      "0  -941.260925   398.620911     8.151943  -878.432739  0.0003  \n",
      "1  -941.144836   398.574951     7.936402  -878.594360  0.0018  \n",
      "2  -941.053223   398.528259     7.658311  -878.786743  0.0033  \n",
      "3  -941.067566   398.522369     8.077589  -878.528381  0.0048  \n",
      "4  -941.057373   398.395020     7.763786  -878.624695  0.0063  \n",
      "\n",
      "[5 rows x 215 columns]\n",
      "\n",
      "Processing trial: 03\n",
      "Trial 03 has 29112 common headers, proceeding with merge.\n",
      "Number of NaN values in merged_sensor_data before merging with conditions: 5039660\n",
      "NaN values detected in merged data for trial 03, dropping rows with NaN.\n",
      "Number of NaN values in merged_data for trial 03 after dropping: 0\n",
      "First few rows of merged data for trial 03:\n",
      "   Header  gastrocmed  tibialisanterior    soleus  vastusmedialis  \\\n",
      "0   8.855    0.264365          0.222178  0.225205        0.218375   \n",
      "1   8.860    0.054146          0.049953  0.040489        0.052677   \n",
      "2   8.865   -0.002267         -0.028988 -0.002840       -0.022513   \n",
      "3   8.870   -0.053773         -0.040784 -0.134016       -0.039847   \n",
      "4   8.875   -0.038269         -0.052816  0.073324       -0.046266   \n",
      "\n",
      "   vastuslateralis  rectusfemoris  bicepsfemoris  semitendinosus  gracilis  \\\n",
      "0         0.221843       0.234636       0.247578        0.224288  0.231081   \n",
      "1         0.045011       0.039861       0.050486        0.045954  0.048986   \n",
      "2        -0.023261      -0.010985      -0.006298       -0.031117 -0.013986   \n",
      "3        -0.042399      -0.061379      -0.050927       -0.046170 -0.050297   \n",
      "4        -0.058564      -0.054535      -0.031636       -0.042371 -0.059458   \n",
      "\n",
      "   ...  L_Toe_Med_x  L_Toe_Med_y  L_Toe_Med_z  L_Toe_Lat_x  L_Toe_Lat_y  \\\n",
      "0  ...   527.559875    13.595472  -876.614807   420.211212     6.383937   \n",
      "1  ...   527.453735    13.480202  -876.648560   420.174530     6.392478   \n",
      "2  ...   527.392212    13.340964  -876.733704   420.162659     6.274715   \n",
      "3  ...   527.340637    13.264588  -876.755188   420.218536     6.443122   \n",
      "4  ...   527.460571    13.509580  -876.638855   420.244965     6.427336   \n",
      "\n",
      "   L_Toe_Lat_z  R_Thigh_Front_x  R_Thigh_Front_y  R_Thigh_Front_z  Speed  \n",
      "0  -818.682129       766.894470       762.709045      -826.573242    0.0  \n",
      "1  -818.694580       767.046387       762.747803      -826.302429    0.0  \n",
      "2  -818.770569       767.104187       762.844971      -826.341309    0.0  \n",
      "3  -818.635742       766.954773       762.799377      -826.387329    0.0  \n",
      "4  -818.634155       766.825500       762.672241      -826.441833    0.0  \n",
      "\n",
      "[5 rows x 215 columns]\n",
      "\n",
      "Processing trial: 04\n",
      "Trial 04 has 28713 common headers, proceeding with merge.\n",
      "Number of NaN values in merged_sensor_data before merging with conditions: 5101921\n",
      "NaN values detected in merged data for trial 04, dropping rows with NaN.\n",
      "Number of NaN values in merged_data for trial 04 after dropping: 0\n",
      "First few rows of merged data for trial 04:\n",
      "      Header  gastrocmed  tibialisanterior    soleus  vastusmedialis  \\\n",
      "781   16.380   -0.009380         -0.026690 -0.048865        0.022497   \n",
      "3770  31.325   -0.006244          0.010059  0.165180        0.003585   \n",
      "3771  31.330   -0.014402          0.006218  0.040996        0.007509   \n",
      "\n",
      "      vastuslateralis  rectusfemoris  bicepsfemoris  semitendinosus  gracilis  \\\n",
      "781         -0.015862      -0.006645       0.010072       -0.011161  0.015413   \n",
      "3770         0.018562      -0.004369       0.008553       -0.009085  0.042732   \n",
      "3771        -0.003902      -0.002878       0.012170       -0.005591  0.017345   \n",
      "\n",
      "      ...  L_Toe_Med_x  L_Toe_Med_y  L_Toe_Med_z  L_Toe_Lat_x  L_Toe_Lat_y  \\\n",
      "781   ...   526.542786    11.373097  -848.490601   422.326538    12.080539   \n",
      "3770  ...   529.777100    62.616566 -1317.269165   434.735840    34.787682   \n",
      "3771  ...   532.569275    84.968590 -1368.846313   436.268250    52.295677   \n",
      "\n",
      "      L_Toe_Lat_z      C_28_x      C_28_y       C_28_z  Speed  \n",
      "781   -794.171631  775.691040  810.929504 -1044.230103   0.65  \n",
      "3770 -1263.306885  731.197144  983.404846  -987.621521   0.65  \n",
      "3771 -1320.860352  729.163269  975.948975  -988.384033   0.65  \n",
      "\n",
      "[3 rows x 218 columns]\n",
      "\n",
      "Processing trial: 05\n",
      "Trial 05 has 28744 common headers, proceeding with merge.\n",
      "Number of NaN values in merged_sensor_data before merging with conditions: 4959304\n",
      "NaN values detected in merged data for trial 05, dropping rows with NaN.\n",
      "Number of NaN values in merged_data for trial 05 after dropping: 0\n",
      "First few rows of merged data for trial 05:\n",
      "   Header  gastrocmed  tibialisanterior    soleus  vastusmedialis  \\\n",
      "0  15.235   -0.008029         -0.009158  0.098197        0.006099   \n",
      "1  15.240   -0.013740          0.003312 -0.084063        0.048663   \n",
      "2  15.245   -0.002905          0.001471 -0.015114       -0.052530   \n",
      "3  15.250    0.009839         -0.011809  0.041994       -0.001992   \n",
      "4  15.255    0.019873         -0.006402 -0.088966       -0.011528   \n",
      "\n",
      "   vastuslateralis  rectusfemoris  bicepsfemoris  semitendinosus  gracilis  \\\n",
      "0         0.007495       0.011644       0.005035       -0.014857  0.005291   \n",
      "1        -0.006552      -0.004423       0.003693       -0.001915  0.004576   \n",
      "2        -0.002793       0.008418      -0.001561       -0.007995  0.007863   \n",
      "3        -0.004615       0.011826      -0.009491       -0.010408  0.002978   \n",
      "4        -0.023671      -0.003150      -0.002547       -0.002369 -0.014374   \n",
      "\n",
      "   ...  L_Toe_Med_x  L_Toe_Med_y  L_Toe_Med_z  L_Toe_Lat_x  L_Toe_Lat_y  \\\n",
      "0  ...   494.850159    12.724066  -890.992920   389.210815     7.017200   \n",
      "1  ...   494.705902    12.548020  -891.111084   389.257416     7.330194   \n",
      "2  ...   494.806152    12.532653  -891.112305   389.281219     7.259133   \n",
      "3  ...   494.826813    12.601948  -891.056580   389.260315     7.197317   \n",
      "4  ...   494.585815    12.440962  -891.172546   389.269135     7.167818   \n",
      "\n",
      "   L_Toe_Lat_z  L_Thigh_Front_x  L_Thigh_Front_y  L_Thigh_Front_z   Speed  \n",
      "0  -829.263062       376.613159       780.684448      -806.921387  0.0012  \n",
      "1  -828.916992       376.072449       780.998352      -806.997498  0.0027  \n",
      "2  -829.098083       376.708649       780.802490      -807.332703  0.0042  \n",
      "3  -829.051331       376.534332       780.661011      -807.435364  0.0057  \n",
      "4  -829.264404       376.357086       780.619934      -807.585388  0.0072  \n",
      "\n",
      "[5 rows x 215 columns]\n",
      "\n",
      "Processing trial: 06\n",
      "Trial 06 has 28778 common headers, proceeding with merge.\n",
      "Number of NaN values in merged_sensor_data before merging with conditions: 4975354\n",
      "NaN values detected in merged data for trial 06, dropping rows with NaN.\n",
      "Number of NaN values in merged_data for trial 06 after dropping: 0\n",
      "First few rows of merged data for trial 06:\n",
      "   Header  gastrocmed  tibialisanterior    soleus  vastusmedialis  \\\n",
      "0  11.155   -0.007621          0.000522 -0.038544        0.001381   \n",
      "1  11.160    0.009518         -0.016718 -0.053777       -0.018065   \n",
      "2  11.165   -0.001419         -0.015921  0.124366       -0.000535   \n",
      "3  11.170    0.015755          0.012767 -0.175272        0.000848   \n",
      "4  11.175   -0.009186          0.008326 -0.061626        0.031676   \n",
      "\n",
      "   vastuslateralis  rectusfemoris  bicepsfemoris  semitendinosus  gracilis  \\\n",
      "0         0.011152       0.001713      -0.017526        0.005102  0.030278   \n",
      "1         0.005202       0.011199       0.007808       -0.001695 -0.014083   \n",
      "2         0.016270      -0.011171      -0.014719       -0.012370  0.021887   \n",
      "3        -0.010229      -0.015453       0.010427        0.007573 -0.024416   \n",
      "4         0.001680      -0.017291       0.000566        0.003518 -0.008712   \n",
      "\n",
      "   ...  L_Toe_Tip_x  L_Toe_Tip_y  L_Toe_Tip_z  L_Toe_Med_x  L_Toe_Med_y  \\\n",
      "0  ...   490.562408    35.331039  -911.041016   518.938843    13.093361   \n",
      "1  ...   490.651794    35.346409  -911.012024   518.886475    13.000299   \n",
      "2  ...   490.635101    35.329998  -910.992249   518.952393    13.082094   \n",
      "3  ...   490.641968    35.401859  -910.951111   518.916321    13.068219   \n",
      "4  ...   490.610870    35.420933  -910.927246   518.879272    13.162380   \n",
      "\n",
      "   L_Toe_Med_z  L_Toe_Lat_x  L_Toe_Lat_y  L_Toe_Lat_z   Speed  \n",
      "0  -915.945251   414.042206     6.426023  -853.586548  0.0009  \n",
      "1  -915.972900   414.070068     6.417998  -853.593933  0.0024  \n",
      "2  -915.908936   414.112366     6.453462  -853.608887  0.0039  \n",
      "3  -915.921204   414.166199     6.578602  -853.611755  0.0054  \n",
      "4  -915.876587   414.180756     6.647968  -853.533386  0.0069  \n",
      "\n",
      "[5 rows x 215 columns]\n",
      "\n",
      "Processing trial: 07\n",
      "Trial 07 has 28813 common headers, proceeding with merge.\n",
      "Number of NaN values in merged_sensor_data before merging with conditions: 4963170\n",
      "NaN values detected in merged data for trial 07, dropping rows with NaN.\n",
      "Number of NaN values in merged_data for trial 07 after dropping: 0\n",
      "First few rows of merged data for trial 07:\n",
      "   Header  gastrocmed  tibialisanterior    soleus  vastusmedialis  \\\n",
      "0   9.845    0.017420          0.010101 -0.022105       -0.008138   \n",
      "1   9.850   -0.041149          0.009673  0.058299        0.008732   \n",
      "2   9.855    0.019074         -0.011388 -0.160004        0.028696   \n",
      "3   9.860    0.006177          0.000672  0.051923       -0.026783   \n",
      "4   9.865   -0.084775         -0.011517  0.117775       -0.007301   \n",
      "\n",
      "   vastuslateralis  rectusfemoris  bicepsfemoris  semitendinosus  gracilis  \\\n",
      "0         0.016758       0.001622      -0.002798        0.006544 -0.003617   \n",
      "1         0.015111      -0.014460      -0.000328        0.008408  0.010064   \n",
      "2         0.000972       0.014569       0.000445       -0.002022  0.020761   \n",
      "3        -0.002894       0.007934      -0.010704        0.006685  0.005045   \n",
      "4        -0.009014       0.000209      -0.015881        0.008474 -0.014091   \n",
      "\n",
      "   ...  L_Toe_Tip_x  L_Toe_Tip_y  L_Toe_Tip_z  L_Toe_Med_x  L_Toe_Med_y  \\\n",
      "0  ...   457.662964    35.727520  -913.727234   486.749908    14.023128   \n",
      "1  ...   457.709991    35.746914  -913.804382   486.679047    13.976224   \n",
      "2  ...   457.781860    35.764370  -913.835022   486.967438    14.206444   \n",
      "3  ...   457.794403    35.758457  -913.842651   486.908356    14.208547   \n",
      "4  ...   457.803070    35.744339  -913.840515   486.702911    14.088198   \n",
      "\n",
      "   L_Toe_Med_z  L_Toe_Lat_x  L_Toe_Lat_y  L_Toe_Lat_z   Speed  \n",
      "0  -919.406372   383.202454     7.778695  -853.830017  0.0009  \n",
      "1  -919.430847   383.208618     7.784137  -853.894470  0.0024  \n",
      "2  -919.534973   383.126801     7.764581  -853.987549  0.0039  \n",
      "3  -919.532227   383.234497     7.921692  -853.930725  0.0054  \n",
      "4  -919.579102   383.286133     7.969983  -853.874939  0.0069  \n",
      "\n",
      "[5 rows x 215 columns]\n",
      "\n",
      "Processing trial: 08\n",
      "Trial 08 has 28845 common headers, proceeding with merge.\n",
      "Number of NaN values in merged_sensor_data before merging with conditions: 4982408\n",
      "NaN values detected in merged data for trial 08, dropping rows with NaN.\n",
      "Number of NaN values in merged_data for trial 08 after dropping: 0\n",
      "First few rows of merged data for trial 08:\n",
      "   Header  gastrocmed  tibialisanterior    soleus  vastusmedialis  \\\n",
      "0  10.680    0.014732         -0.012384  0.009742       -0.022506   \n",
      "1  10.685    0.014889         -0.016062 -0.159918       -0.002427   \n",
      "2  10.690    0.017151         -0.018278  0.023899       -0.021435   \n",
      "3  10.695    0.007545         -0.007756 -0.042259       -0.002982   \n",
      "4  10.700    0.010254         -0.005784  0.082526        0.000845   \n",
      "\n",
      "   vastuslateralis  rectusfemoris  bicepsfemoris  semitendinosus  gracilis  \\\n",
      "0        -0.004258       0.007977       0.006551       -0.020039 -0.006330   \n",
      "1        -0.005621       0.002715      -0.012533       -0.000243 -0.005403   \n",
      "2        -0.002280       0.001163       0.008203       -0.012035  0.004883   \n",
      "3        -0.004387       0.004022      -0.008752       -0.004259  0.001812   \n",
      "4        -0.005987       0.017089       0.015851       -0.011337  0.001551   \n",
      "\n",
      "   ...  L_Toe_Tip_x  L_Toe_Tip_y  L_Toe_Tip_z  L_Toe_Med_x  L_Toe_Med_y  \\\n",
      "0  ...   504.008453    35.649403  -829.907715   532.540833    13.334341   \n",
      "1  ...   503.992676    35.586540  -829.835144   532.529236    13.330085   \n",
      "2  ...   504.086517    35.622581  -829.852722   532.523865    13.288137   \n",
      "3  ...   504.322784    35.541035  -829.928894   532.619934    13.260223   \n",
      "4  ...   504.358765    35.529041  -829.940552   532.544617    13.238019   \n",
      "\n",
      "   L_Toe_Med_z  L_Toe_Lat_x  L_Toe_Lat_y  L_Toe_Lat_z   Speed  \n",
      "0  -833.025146   423.316315     5.483741  -778.868774  0.0006  \n",
      "1  -833.007019   423.170685     4.427039  -779.746033  0.0021  \n",
      "2  -832.994751   423.183716     4.541997  -779.698303  0.0036  \n",
      "3  -833.012085   423.124115     4.603978  -779.645813  0.0051  \n",
      "4  -833.031372   423.298492     5.321746  -778.942444  0.0066  \n",
      "\n",
      "[5 rows x 215 columns]\n",
      "Shape of Xs after filtering common headers: [(4916, 214), (5121, 214), (5265, 214), (5149, 214), (5380, 214), (5219, 214)]\n",
      "Shape of ys: [(4916,), (5121,), (5265,), (5149,), (5380,), (5219,)]\n",
      "Number of NaN values in X: 0\n",
      "Number of NaN values in y: 0\n",
      "Number of infinite values in X: 0\n",
      "Number of infinite values in y: 0\n"
     ]
    }
   ],
   "source": [
    "# Define which sensors you want to use\n",
    "sensors_to_use = [\n",
    "    \"emg\",\n",
    "    \"fp\",\n",
    "    \"gcLeft\",\n",
    "    \"gcRight\",\n",
    "    \"gon\",\n",
    "    \"id\",\n",
    "    \"ik\",\n",
    "    \"ik_offset\",\n",
    "    \"imu\",\n",
    "    \"jp\",\n",
    "    \"markers\",\n",
    "]\n",
    "\n",
    "base_dir = \"datasetcsv_output\"\n",
    "\n",
    "trials = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\"]\n",
    "\n",
    "# To store X and y for each trial\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "# Load each dataset and process independently\n",
    "for trial in trials:\n",
    "    print(f\"\\nProcessing trial: {trial}\")\n",
    "    sensor_data_list = []\n",
    "    trial_common_headers = None\n",
    "\n",
    "    # Load each sensor data\n",
    "    for sensor in sensors_to_use:\n",
    "        sensor_file = f\"{sensor}_treadmill_{trial}_01.csv\"\n",
    "        sensor_path = os.path.join(base_dir, sensor_file)\n",
    "        if os.path.exists(sensor_path):\n",
    "            df_sensor = pd.read_csv(sensor_path)\n",
    "            sensor_data_list.append(df_sensor)\n",
    "\n",
    "            if trial_common_headers is None:\n",
    "                trial_common_headers = set(df_sensor[\"Header\"])\n",
    "            else:\n",
    "                trial_common_headers.intersection_update(df_sensor[\"Header\"])\n",
    "\n",
    "    conditions_file = f\"conditions_treadmill_{trial}_01.csv\"\n",
    "    conditions_path = os.path.join(base_dir, conditions_file)\n",
    "    if os.path.exists(conditions_path):\n",
    "        df_conditions = pd.read_csv(conditions_path)\n",
    "\n",
    "        if trial_common_headers is not None:\n",
    "            trial_common_headers.intersection_update(df_conditions[\"Header\"])\n",
    "\n",
    "    if trial_common_headers and sensor_data_list:\n",
    "        print(\n",
    "            f\"Trial {trial} has {len(trial_common_headers)} common headers, proceeding with merge.\"\n",
    "        )\n",
    "\n",
    "        filtered_sensor_data = [\n",
    "            df[df[\"Header\"].isin(trial_common_headers)].sort_values(by=\"Header\")\n",
    "            for df in sensor_data_list\n",
    "        ]\n",
    "        filtered_conditions = df_conditions[\n",
    "            df_conditions[\"Header\"].isin(trial_common_headers)\n",
    "        ].sort_values(by=\"Header\")\n",
    "\n",
    "        # Merge all filtered sensor data for this trial\n",
    "        merged_sensor_data = pd.concat(filtered_sensor_data, axis=1)\n",
    "\n",
    "        # Drop duplicated 'Header' columns except for the first one\n",
    "        merged_sensor_data = merged_sensor_data.loc[\n",
    "            :, ~merged_sensor_data.columns.duplicated()\n",
    "        ]\n",
    "\n",
    "        print(\n",
    "            f\"Number of NaN values in merged_sensor_data before merging with conditions: {merged_sensor_data.isna().sum().sum()}\"\n",
    "        )\n",
    "\n",
    "        # Merge sensor and conditions data for this trial using an inner join to avoid NaN\n",
    "        merged_data_trial = pd.merge(\n",
    "            merged_sensor_data, filtered_conditions, on=\"Header\", how=\"inner\"\n",
    "        )\n",
    "\n",
    "        # Drop any remaining NaN values after merging\n",
    "        if merged_data_trial.isna().sum().sum() > 0:\n",
    "            print(\n",
    "                f\"NaN values detected in merged data for trial {trial}, dropping rows with NaN.\"\n",
    "            )\n",
    "            merged_data_trial = merged_data_trial.dropna()\n",
    "\n",
    "        # Extract features (X) and target (y) for the trial\n",
    "        X_trial = merged_data_trial.drop(columns=[\"Speed\"])\n",
    "        y_trial = merged_data_trial[\"Speed\"]\n",
    "\n",
    "        # Append to the list for all trials\n",
    "        X_list.append(X_trial)\n",
    "        y_list.append(y_trial)\n",
    "\n",
    "        # Print the number of NaN values after dropping NaN rows\n",
    "        print(\n",
    "            f\"Number of NaN values in merged_data for trial {trial} after dropping: {merged_data_trial.isna().sum().sum()}\"\n",
    "        )\n",
    "\n",
    "        # Print the first few rows of the merged data for inspection\n",
    "        print(\n",
    "            f\"First few rows of merged data for trial {trial}:\\n{merged_data_trial.head()}\"\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print(f\"Trial {trial} skipped due to no common headers or missing sensor data.\")\n",
    "\n",
    "# Ensure consistency across trials by keeping only columns that are common across all trials\n",
    "common_headers = {col for X_trial in X_list for col in X_trial.columns}\n",
    "for X_trial in X_list:\n",
    "    common_headers.intersection_update(X_trial.columns)\n",
    "\n",
    "# Filter X to keep only common columns across all trials\n",
    "X_list = [X_trial[list(common_headers)] for X_trial in X_list]\n",
    "\n",
    "# Filter out trials with less than 100 timesteps\n",
    "X_list = [X_trial for X_trial in X_list if len(X_trial) >= 100]\n",
    "y_list = [y_trial for y_trial in y_list if len(y_trial) >= 100]\n",
    "\n",
    "# Print the shape of X and y\n",
    "print(\n",
    "    f\"Shape of Xs after filtering common headers: {[X_trial.shape for X_trial in X_list]}\"\n",
    ")\n",
    "print(f\"Shape of ys: {[y_trial.shape for y_trial in y_list]}\")\n",
    "\n",
    "# Check for NaN values in X and y\n",
    "nan_count_X = sum(X_trial.isna().sum().sum() for X_trial in X_list)\n",
    "nan_count_y = sum(y_trial.isna().sum() for y_trial in y_list)\n",
    "\n",
    "print(f\"Number of NaN values in X: {nan_count_X}\")\n",
    "print(f\"Number of NaN values in y: {nan_count_y}\")\n",
    "\n",
    "# Check for infinite values in X and y\n",
    "inf_count_X = sum(np.isinf(X_trial.values).sum() for X_trial in X_list)\n",
    "inf_count_y = sum(np.isinf(y_trial).sum() for y_trial in y_list)\n",
    "\n",
    "print(f\"Number of infinite values in X: {inf_count_X}\")\n",
    "print(f\"Number of infinite values in y: {inf_count_y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shapes:\n",
      "\tX: (30672, 214, 64)\n",
      "\ty: (30672,)\n"
     ]
    }
   ],
   "source": [
    "stack_size = 64\n",
    "\n",
    "\n",
    "def sliding_window(X_trial):\n",
    "    slidified = np.lib.stride_tricks.sliding_window_view(X_trial, stack_size, -2)\n",
    "\n",
    "    return slidified\n",
    "\n",
    "\n",
    "X = np.concat(\n",
    "    [\n",
    "        sliding_window(X_trial)\n",
    "        for X_trial in X_list\n",
    "    ]\n",
    ")\n",
    "y = np.concat([y_trial[stack_size - 1 :] for y_trial in y_list])\n",
    "\n",
    "print(f\"Final shapes:\\n\\tX: {X.shape}\\n\\ty: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8QtDPJqmsZ5S"
   },
   "outputs": [],
   "source": [
    "# Convert to NumPy arrays if needed\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Custom Dataset Class\n",
    "class SpeedDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.astype(np.float32)).to(device)\n",
    "        self.y = torch.from_numpy(y.astype(np.float32)).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "# Create Datasets and DataLoaders\n",
    "train_dataset = SpeedDataset(X_train, y_train)\n",
    "val_dataset = SpeedDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fq7E3rklsdG3"
   },
   "outputs": [],
   "source": [
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, kernel_size, stride, dilation, dropout=0.2\n",
    "    ):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        # Calculate padding to keep output size the same as input size\n",
    "        padding = (kernel_size - 1) * dilation\n",
    "\n",
    "        # First convolution layer\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Second convolution layer\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            *(self.conv1, self.bn1, self.relu, self.dropout),\n",
    "            *(self.conv2, self.bn2, self.relu, self.dropout),\n",
    "        )\n",
    "\n",
    "        # Residual connection\n",
    "        self.downsample = (\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "            if in_channels != out_channels\n",
    "            else None\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        # Slice output to match input length (in case padding added extra time steps)\n",
    "        out = out[..., : x.size(-1)]\n",
    "        return self.relu(out + x)\n",
    "\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=3, dropout=0.2):\n",
    "        super(TCN, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2**i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i - 1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [\n",
    "                TemporalBlock(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size,\n",
    "                    stride=1,\n",
    "                    dilation=dilation_size,\n",
    "                    dropout=dropout,\n",
    "                ),\n",
    "                # Strided convolution to downscale\n",
    "                nn.Conv1d(out_channels, out_channels, 5, 3),\n",
    "            ]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        self.linear = nn.Linear(num_channels[-1], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: [batch_size, channels, timesteps]\n",
    "        y = self.network(x)\n",
    "        y = y[..., -1]  # Take the last time step output\n",
    "        return self.linear(y)[..., 0] # Squeeze the last dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 172037,
     "status": "ok",
     "timestamp": 1731101851189,
     "user": {
      "displayName": "Fatima Tourk",
      "userId": "02048723961878231607"
     },
     "user_tz": 300
    },
    "id": "cTyHDbslshxW",
    "outputId": "8dd401ad-2c5e-4c48-f925-b92094abb648"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61fe8e278014455afcaa22d52162028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Instantiate the model, loss, and optimizer\n",
    "num_features = X_train.shape[-2]  # Number of features as the input channels\n",
    "model = TCN(\n",
    "    num_inputs=num_features,\n",
    "    num_channels=[128, 128, 128],\n",
    "    kernel_size=7,\n",
    "    dropout=0.2,\n",
    ").to(device)\n",
    "criterion = nn.MSELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 256\n",
    "\n",
    "pbar = tqdm(total=num_epochs)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    running_train_count = 0\n",
    "\n",
    "    # Wrap train_loader with tqdm to show progress\n",
    "    for X_batch, y_batch in tqdm(\n",
    "        train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\", disable=True\n",
    "    ):\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs.squeeze(), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "        running_train_count += np.ones_like(y_batch.detach().cpu().numpy()).sum()\n",
    "\n",
    "    epoch_loss = running_train_loss / running_train_count\n",
    "    # print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    running_val_count = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs.squeeze(), y_batch)\n",
    "            running_val_loss += loss.item()\n",
    "            running_val_count += np.ones_like(y_batch.cpu().numpy()).sum()\n",
    "\n",
    "    val_loss = running_val_loss / running_val_count\n",
    "    # print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "    pbar.update()\n",
    "\n",
    "    pbar.set_postfix(\n",
    "        {\n",
    "            \"Train Loss\": f\"{epoch_loss:.4f}\",\n",
    "            \"Val Loss\": f\"{val_loss:.4f}\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FljJQEgmslYQ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpytorch_model_to_jax\u001b[39m(torch_model: \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSequential):\n\u001b[1;32m      2\u001b[0m     params \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m     act \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "def pytorch_model_to_jax(torch_model: torch.nn.Sequential):\n",
    "    params = []\n",
    "    act = None\n",
    "\n",
    "    # Extract params (weights, biases) from torch layers, to be used in\n",
    "    # jax.\n",
    "    # Note: This propagator assumes a feed-forward relu NN.\n",
    "    for m in torch_model.modules():\n",
    "        if isinstance(m, torch.nn.Sequential):\n",
    "            continue\n",
    "        elif isinstance(m, torch.nn.ReLU):\n",
    "            if act is None or act == \"relu\":\n",
    "                act = \"relu\"\n",
    "        elif isinstance(m, torch.nn.Linear):\n",
    "            w = m.weight.data.cpu().numpy().T\n",
    "            b = m.bias.data.cpu().numpy()\n",
    "            params.append((w, b))\n",
    "    return functools.partial(relu_nn, params)\n",
    "\n",
    "\n",
    "def relu_nn(params, inputs):\n",
    "    for W, b in params[:-1]:\n",
    "        outputs = jnp.dot(inputs, W) + b\n",
    "        inputs = jnp.maximum(outputs, 0)\n",
    "    W, b = params[-1]\n",
    "    return jnp.dot(inputs, W) + b\n",
    "\n",
    "\n",
    "def jax_interval_to_np_range(interval: jax_verify.IntervalBound) -> np.ndarray:\n",
    "    return np.vstack([interval.lower, interval.upper]).T\n",
    "\n",
    "\n",
    "def np_range_to_jax_interval(input_range: np.ndarray) -> jax_verify.IntervalBound:\n",
    "    return jax_verify.IntervalBound(input_range[:, 0], input_range[:, 1])\n",
    "\n",
    "\n",
    "jax_model = pytorch_model_to_jax(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KdqOLxbGviEk"
   },
   "outputs": [],
   "source": [
    "def nominal_and_epsilon_to_range(nominal: np.ndarray, epsilon: np.ndarray | float) -> np.ndarray:\n",
    "  return np.vstack([nominal-epsilon, nominal+epsilon]).T\n",
    "\n",
    "def range_to_nominal_and_epsilon(input_range: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "  nominal_input = (input_range[:, 1] + input_range[:, 0]) / 2.\n",
    "  epsilon = (input_range[:, 1] - input_range[:, 0]) / 2.\n",
    "  return nominal_input, epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "K7g_1g_vtpkR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Extract inputs from the validation dataset and convert to NumPy\n",
    "val_X_all = torch.stack([val_dataset[i][0] for i in range(len(val_dataset))]).squeeze(-1)\n",
    "nominal_input = val_X_all.numpy()\n",
    "\n",
    "# Define epsilon for input perturbation (this could be a scalar or an array)\n",
    "epsilon = 0.05  # Example value, adjust as needed\n",
    "\n",
    "# Use the provided function to convert nominal inputs and epsilon to a range\n",
    "input_range = nominal_and_epsilon_to_range(nominal_input, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "executionInfo": {
     "elapsed": 360,
     "status": "error",
     "timestamp": 1731102693799,
     "user": {
      "displayName": "Fatima Tourk",
      "userId": "02048723961878231607"
     },
     "user_tz": 300
    },
    "id": "1eF2_WXWwnbU",
    "outputId": "b2c96477-bc34-46f0-9d5e-31953bbc245a"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dot_general requires contracting dimensions to have the same shape, got (214,) and (64,).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example of computing bounds using IBP as implemented by jax_verify\u001b[39;00m\n\u001b[1;32m      2\u001b[0m input_bounds \u001b[38;5;241m=\u001b[39m np_range_to_jax_interval(input_range)\n\u001b[0;32m----> 3\u001b[0m output_bounds_ibp_jax \u001b[38;5;241m=\u001b[39m \u001b[43mjax_verify\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterval_bound_propagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjax_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_bounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m output_range_ibp_jax \u001b[38;5;241m=\u001b[39m jax_interval_to_np_range(output_bounds_ibp_jax)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput bounds via IBP (jax_verify): \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00moutput_range_ibp_jax\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/venvs/treadmill/lib/python3.12/site-packages/jax_verify/src/ibp.py:485\u001b[0m, in \u001b[0;36minterval_bound_propagation\u001b[0;34m(function, *bounds)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterval_bound_propagation\u001b[39m(function, \u001b[38;5;241m*\u001b[39mbounds):\n\u001b[1;32m    476\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Performs IBP as described in https://arxiv.org/abs/1810.12715.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \n\u001b[1;32m    478\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;124;03m    output_bound: Bounds on the output of the function obtained by IBP\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 485\u001b[0m   output_bound, _ \u001b[38;5;241m=\u001b[39m \u001b[43mbound_propagation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound_propagation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbound_propagation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mForwardPropagationAlgorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbound_transform\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m output_bound\n",
      "File \u001b[0;32m~/venvs/treadmill/lib/python3.12/site-packages/jax_verify/src/bound_propagation.py:222\u001b[0m, in \u001b[0;36mbound_propagation\u001b[0;34m(prop_alg, function, graph_simplifier, *bounds)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Parse the computation graph.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m placeholder_inputs \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_map(\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m b: b\u001b[38;5;241m.\u001b[39mlower \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, Bound) \u001b[38;5;28;01melse\u001b[39;00m b,\n\u001b[1;32m    221\u001b[0m     bounds)\n\u001b[0;32m--> 222\u001b[0m parsed \u001b[38;5;241m=\u001b[39m \u001b[43msynthetic_primitives\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_jaxpr_nojit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mplaceholder_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m output_shapes \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39meval_shape(function, \u001b[38;5;241m*\u001b[39mplaceholder_inputs)\n\u001b[1;32m    225\u001b[0m flat_is_bound, _ \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_flatten(\n\u001b[1;32m    226\u001b[0m     jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_map(\u001b[38;5;28;01mlambda\u001b[39;00m b: \u001b[38;5;28misinstance\u001b[39m(b, Bound), bounds))\n",
      "File \u001b[0;32m~/venvs/treadmill/lib/python3.12/site-packages/jax_verify/src/synthetic_primitives.py:48\u001b[0m, in \u001b[0;36mmake_jaxpr_nojit\u001b[0;34m(fun, *inps, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mdisable_jit():\n\u001b[1;32m     47\u001b[0m   make_jaxpr \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mmake_jaxpr(kwarged_fun)\n\u001b[0;32m---> 48\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_jaxpr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minps\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[14], line 26\u001b[0m, in \u001b[0;36mrelu_nn\u001b[0;34m(params, inputs)\u001b[0m\n\u001b[1;32m     24\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mmaximum(outputs, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     25\u001b[0m W, b \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b\n",
      "File \u001b[0;32m~/venvs/treadmill/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:8722\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(a, b, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m   8720\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   8721\u001b[0m     contract_dims \u001b[38;5;241m=\u001b[39m ((a_ndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,), (b_ndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m,))\n\u001b[0;32m-> 8722\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimension_numbers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcontract_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dims\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8723\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8724\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mpreferred_element_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreferred_element_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   8725\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lax_internal\u001b[38;5;241m.\u001b[39m_convert_element_type(result, preferred_element_type,\n\u001b[1;32m   8726\u001b[0m                                           output_weak_type)\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[0;32m~/venvs/treadmill/lib/python3.12/site-packages/jax/_src/lax/lax.py:3241\u001b[0m, in \u001b[0;36m_dot_general_shape_rule\u001b[0;34m(lhs, rhs, dimension_numbers, precision, preferred_element_type, out_type)\u001b[0m\n\u001b[1;32m   3238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m core\u001b[38;5;241m.\u001b[39mdefinitely_equal_shape(lhs_contracting_shape, rhs_contracting_shape):\n\u001b[1;32m   3239\u001b[0m   msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdot_general requires contracting dimensions to have the same \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3240\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 3241\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(lhs_contracting_shape, rhs_contracting_shape))\n\u001b[1;32m   3243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _dot_general_shape_computation(lhs\u001b[38;5;241m.\u001b[39mshape, rhs\u001b[38;5;241m.\u001b[39mshape, dimension_numbers)\n",
      "\u001b[0;31mTypeError\u001b[0m: dot_general requires contracting dimensions to have the same shape, got (214,) and (64,)."
     ]
    }
   ],
   "source": [
    "# Example of computing bounds using IBP as implemented by jax_verify\n",
    "input_bounds = np_range_to_jax_interval(input_range)\n",
    "output_bounds_ibp_jax = jax_verify.interval_bound_propagation(jax_model, input_bounds)\n",
    "output_range_ibp_jax = jax_interval_to_np_range(output_bounds_ibp_jax)\n",
    "print(f\"output bounds via IBP (jax_verify): \\n{output_range_ibp_jax}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRf1om47uqb_"
   },
   "outputs": [],
   "source": [
    "num_trials = 10000\n",
    "successful_trials = 0\n",
    "\n",
    "for _ in range(num_trials):\n",
    "    perturbed_inputs = inputs + jax.random.normal(jax.random.PRNGKey(0), inputs.shape) * epsilon\n",
    "    predictions = model_function(params, perturbed_inputs)\n",
    "    within_bounds = jnp.logical_and(predictions >= target_lb, predictions <= target_ub)\n",
    "    if jnp.all(within_bounds):\n",
    "        successful_trials += 1\n",
    "\n",
    "empirical_verification_percentage = (successful_trials / num_trials) * 100\n",
    "\n",
    "if empirical_verification_percentage >= 99:\n",
    "    print(\"Empirically verified: Model predicts within 0.1 m/s for 99% of the perturbed inputs.\")\n",
    "else:\n",
    "    print(f\"Empirical verification failed. Only {empirical_verification_percentage}% of predictions are within the target range.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNDEH95r1sxW8nwPvqt9s8W",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "treadmill",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
